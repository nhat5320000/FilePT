import cv2
import torch
import uvicorn
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse, HTMLResponse
from ultralytics import YOLO

# Initialize FastAPI app
app = FastAPI()

# Global variable for YOLO model
detect_model = None  # YOLO-based object detection model

def generate_video(source: str, detect_conf: float) -> Generator[bytes, None, None]:
    """
    Stream video frames with object detection using YOLO.

    Args:
        source (str): Video source (camera index or file path).
        detect_conf (float): Confidence threshold for detection.

    Yields:
        bytes: Encoded video frame.
    """
    global detect_model

    # Initialize video source
    video_source = int(source) if source.isdigit() else source
    cap = cv2.VideoCapture(video_source)

    if not cap.isOpened():
        raise HTTPException(status_code=404, detail="Source not found or cannot be accessed.")

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # Perform object detection
        detect_results = detect_model.predict(source=frame, stream=True, conf=detect_conf, imgsz=320, save=False)

        for detect_result in detect_results:
            boxes = detect_result.boxes.xyxy.cpu().to(dtype=torch.int).tolist()
            labels = detect_result.boxes.cls.cpu().tolist()
            confidences = detect_result.boxes.conf.cpu().tolist()

            if not boxes:
                print("Warning: No objects detected")
                cv2.putText(frame, "No objects", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                continue

            for box, label, confidence in zip(boxes, labels, confidences):
                # Draw bounding box and label
                color = (0, 255, 0)  # Green for all objects
                cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), color, 2)
                cv2.putText(
                    frame,
                    f"Class {int(label)}: {confidence:.2f}",  # Hiển thị class và độ tin cậy
                    (box[0], box[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    color,
                    2
                )

        # Encode the frame for streaming
        _, buffer = cv2.imencode('.jpg', frame)
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')

    cap.release()

@app.on_event("startup")
def load_models():
    """
    Load YOLO model during application startup.
    """
    global detect_model

    # Load YOLO model (đảm bảo model đã được train với 5 classes)
    detect_model = YOLO("training/object-detect/yolov11n/yolov11_last.engine", task='detect')

    # Test inference
    test_image = torch.rand(1, 3, 320, 320, dtype=torch.float32)
    results = detect_model(test_image, imgsz=320)
    print("YOLO test result:", results)

@app.get("/video_feed")
def video_feed():
    """
    Serve the video feed with object detection.
    """
    return StreamingResponse(
        generate_video(source="0", detect_conf=0.7),
        media_type="multipart/x-mixed-replace; boundary=frame"
    )

@app.get("/", response_class=HTMLResponse)
async def home():
    """
    Serve the home page.
    """
    return HTMLResponse(content=open("src/index.html").read())

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
